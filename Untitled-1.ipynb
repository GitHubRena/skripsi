{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from collections import Counter\n",
    "\n",
    "from early_stopping import EarlyStopping  # Import early stopping class\n",
    "# GPU Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# Custom Dataset Class\n",
    "# -------------------------------------------------\n",
    "class FundusDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None, for_model='inception'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): Path to the CSV file containing image metadata.\n",
    "            img_dir (str): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "            for_model (str): Target model ('inception' or 'densenet121').\n",
    "        \"\"\"\n",
    "        self.label_df = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.for_model = for_model.lower()  # Ensure consistent lowercase\n",
    "        self.label_severity = self.label_df['adjudicated_dr_grade'].values  # Adjust this line if necessary\n",
    "    def __len__(self):\n",
    "        return len(self.label_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch image ID and label\n",
    "        img_id = str(self.label_df.iloc[idx, 0])\n",
    "        img_path = os.path.join(self.img_dir, img_id)\n",
    "        original_label = self.label_df.iloc[idx, 1]\n",
    "        # Load image\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f'Image not found: {img_path}')\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f'Error reading image: {img_path}')\n",
    "        \n",
    "        # Preprocess image\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Extract the green channel first (\"terlihat hijau\" (tetapi sebenarnya seluruh citra akan terlihat abu-abu karena semua saluran memiliki nilai yang sama))\n",
    "        green_channel = image_rgb[:, :, 1]\n",
    "        green_channel_image = np.stack((green_channel, green_channel, green_channel), axis=-1)\n",
    "        image_clahe = self._apply_clahe(green_channel_image)\n",
    "        image_sharpened = self._apply_sharpening(image_clahe)\n",
    "        image_super_res = self._apply_super_resolution(image_sharpened)\n",
    "        \n",
    "        if self.transform:\n",
    "            image_super_res = self.transform(image_super_res)\n",
    "\n",
    "        if self.for_model == 'inception':\n",
    "            label_dr = 0 if original_label == 0 else 1\n",
    "            label_severity = None  # Placeholder\n",
    "        elif self.for_model == 'densenet121':\n",
    "            label_dr = None  # Not required for severity model\n",
    "            label_severity = original_label\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model type: {self.for_model}\")\n",
    "\n",
    "        label_severity = torch.tensor(self.label_severity[idx]).long() if self.label_severity[idx] is not None else torch.tensor(0).long()\n",
    "\n",
    "        return image_super_res,label_dr, label_severity\n",
    "\n",
    "    def _apply_clahe(self, img):\n",
    "        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "        cl = clahe.apply(l)\n",
    "        limg = cv2.merge((cl, a, b))\n",
    "        return cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    def _apply_sharpening(self, img):\n",
    "        kernel = np.array([[0, -0.5, 0], [-0.5, 3, -0.5], [0, -0.5, 0]])\n",
    "        return cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "    def _apply_super_resolution(self, img):\n",
    "        return cv2.resize(img, (299, 299), interpolation=cv2.INTER_CUBIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# calculate mean and resampled data Functions\n",
    "# -------------------------------------------------\n",
    "def calculate_mean_std(dataset):\n",
    "    \"\"\"\n",
    "    Calculate mean and standard deviation for a dataset.\n",
    "    \"\"\"\n",
    "    mean, std = 0.0, 0.0\n",
    "    num_samples = len(dataset)\n",
    "    \n",
    "\n",
    "    for img, _, _ in dataset:\n",
    "        img = img.numpy()\n",
    "        mean += img.mean(axis=(1, 2))\n",
    "        std += img.std(axis=(1, 2))\n",
    "    \n",
    "    mean /= num_samples\n",
    "    std /= num_samples\n",
    "    return mean, std\n",
    "\n",
    "class ResampledDataset(Dataset):\n",
    "    def __init__(self, features, label_dr=None, label_severity=None,is_severity_task=False):\n",
    "        \"\"\"\n",
    "        Dataset wrapper for resampled features and labels.\n",
    "\n",
    "        Args:\n",
    "            features (list or ndarray): Pre-processed features, typically flattened images.\n",
    "            label_dr (list or ndarray, optional): Labels for binary classification (DR/Non-DR).\n",
    "            label_severity (list or ndarray, optional): Labels for severity classification.\n",
    "            is_severity_task (bool): If True, the dataset is used for severity training.\n",
    "        \"\"\"\n",
    "        # assert len(features) > 0, \"Features must not be empty.\"\n",
    "        # if label_dr is not None:\n",
    "        #     assert len(features) == len(label_dr), \"Features and label_dr must have the same length.\"\n",
    "        # # if label_severity is not None:\n",
    "        # #     assert len(features) == len(label_severity), \"Features and label_severity must have the same length.\"\n",
    "\n",
    "        self.features = features\n",
    "        self.label_dr = label_dr\n",
    "        self.label_severity = label_severity\n",
    "        self.is_severity_task = is_severity_task\n",
    "\n",
    "        self.dummy_severity_label = [0] * len(features) if not is_severity_task else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the image\n",
    "        image = torch.tensor(self.features[idx]).reshape(3, 299, 299).float()\n",
    "\n",
    "        # Load labels if they exist\n",
    "        label_dr = torch.tensor(self.label_dr[idx]).long() if self.label_dr is not None else None\n",
    "        label_severity = (\n",
    "            torch.tensor(self.label_severity[idx]).long()\n",
    "            if self.is_severity_task and self.label_severity is not None\n",
    "            else torch.tensor(0).long()\n",
    "        )\n",
    "        return image, label_dr, label_severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# Dataset and DataLoader Setup\n",
    "# -------------------------------------------------\n",
    "# File paths\n",
    "csv_file = r'C:\\Users\\renat\\OneDrive\\Documents\\skripsi\\Code\\images_id_kelas.csv'\n",
    "img_dir = r'C:\\Users\\renat\\OneDrive\\Documents\\skripsi\\Code\\HasilCrop299'\n",
    "\n",
    "# Placeholder transform for mean and std calculation\n",
    "temp_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Initialize dataset\n",
    "dataset = FundusDataset(csv_file=csv_file, img_dir=img_dir, transform=temp_transform)\n",
    "mean, std = calculate_mean_std(dataset)\n",
    "\n",
    "# Define actual transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# Dataset for InceptionResNetV2 (binary classification)\n",
    "dataset_inception = FundusDataset(csv_file=csv_file, img_dir=img_dir, transform=transform, for_model='inception')\n",
    "\n",
    "# Extract features and label for binary classification\n",
    "features_inception, label_inception = [], []\n",
    "for img, label_dr, _ in dataset_inception:\n",
    "    features_inception.append(img.numpy().flatten())\n",
    "    label_inception.append(label_dr)\n",
    "\n",
    "# Oversample binary dataset\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled_binary, y_resampled_binary = ros.fit_resample(np.array(features_inception), np.array(label_inception))\n",
    "\n",
    "# Prepare binary dataset\n",
    "\n",
    "resampled_dataset_inception = ResampledDataset(X_resampled_binary, y_resampled_binary, is_severity_task=False)\n",
    "train_size = int(0.8 * len(resampled_dataset_inception))\n",
    "test_size = len(resampled_dataset_inception) - train_size\n",
    "train_dataset_inception, test_dataset_inception = random_split(resampled_dataset_inception, [train_size, test_size])\n",
    "train_loader_inception = DataLoader(train_dataset_inception, batch_size=8, shuffle=True, pin_memory=True)\n",
    "test_loader_inception = DataLoader(test_dataset_inception, batch_size=8, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before resampling: Counter({tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(1): 1, tensor(3): 1, tensor(4): 1, tensor(4): 1, tensor(3): 1, tensor(3): 1, tensor(3): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(3): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(1): 1, tensor(4): 1, tensor(2): 1, tensor(2): 1, tensor(3): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(4): 1, tensor(4): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(3): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(3): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(4): 1, tensor(4): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(3): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(4): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(3): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(2): 1, tensor(3): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(3): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(4): 1, tensor(4): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(4): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(3): 1, tensor(3): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(3): 1, tensor(3): 1, tensor(3): 1, tensor(1): 1, tensor(2): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(4): 1, tensor(4): 1, tensor(4): 1, tensor(3): 1, tensor(3): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(2): 1, tensor(3): 1, tensor(3): 1, tensor(3): 1, tensor(3): 1, tensor(3): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(3): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(2): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(3): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(3): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(3): 1, tensor(3): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(3): 1, tensor(1): 1, tensor(2): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(3): 1, tensor(2): 1, tensor(1): 1, tensor(2): 1, tensor(0): 1, tensor(2): 1, tensor(3): 1, tensor(3): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(1): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(2): 1, tensor(3): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(2): 1, tensor(4): 1, tensor(4): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(3): 1, tensor(3): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(3): 1, tensor(2): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(3): 1, tensor(2): 1, tensor(2): 1, tensor(3): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(1): 1, tensor(3): 1, tensor(3): 1, tensor(3): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(1): 1, tensor(3): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(3): 1, tensor(3): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(3): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(3): 1, tensor(3): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(3): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(0): 1, tensor(1): 1, tensor(3): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(3): 1, tensor(3): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(3): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(4): 1, tensor(4): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(4): 1, tensor(4): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(4): 1, tensor(4): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(4): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(3): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1})\n",
      "After resampling: Counter({0: 886, 1: 886, 2: 886, 3: 886, 4: 886})\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Batch severity label: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Dataset untuk DenseNet121\n",
    "dataset_densenet = FundusDataset(\n",
    "    csv_file=csv_file,\n",
    "    img_dir=img_dir,\n",
    "    transform=transform,\n",
    "    for_model='densenet121'\n",
    ")\n",
    "\n",
    "# Filter and oversample severity dataset\n",
    "features_densenet, label_densenet = [], []\n",
    "for data in dataset_densenet:\n",
    "    img, _, label_severity = data\n",
    "    if label_severity is not None:\n",
    "        features_densenet.append(img.numpy().flatten())\n",
    "        label_densenet.append(label_severity)\n",
    "\n",
    "print(\"Before resampling:\", Counter(label_densenet))\n",
    "\n",
    "_ , y_densenet_resampled = ros.fit_resample(np.array(features_densenet), np.array(label_densenet))\n",
    "resampled_dataset_densenet = ResampledDataset(features_densenet, y_densenet_resampled,is_severity_task=True)\n",
    "print(\"After resampling:\", Counter(y_densenet_resampled))\n",
    "\n",
    "train_size_densenet = int(0.8 * len(resampled_dataset_densenet))\n",
    "test_size_densenet = len(resampled_dataset_densenet) - train_size_densenet\n",
    "train_dataset_densenet, test_dataset_densenet = random_split(resampled_dataset_densenet, [train_size_densenet, test_size_densenet])\n",
    "train_loader_densenet = DataLoader(train_dataset_densenet, batch_size=8, shuffle=True, pin_memory=True)\n",
    "test_loader_densenet = DataLoader(test_dataset_densenet, batch_size=8, shuffle=False, pin_memory=True)\n",
    "for batch in train_loader_densenet:\n",
    "    img,_, label_severity = batch\n",
    "    print(\"Batch severity label:\", label_severity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m ros \u001b[38;5;241m=\u001b[39m RandomOverSampler(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     16\u001b[0m X_resampled_combined, y_resampled_dr_combined \u001b[38;5;241m=\u001b[39m ros\u001b[38;5;241m.\u001b[39mfit_resample(features_combined, label_dr_combined)\n\u001b[1;32m---> 17\u001b[0m _, y_resampled_severity_combined \u001b[38;5;241m=\u001b[39m \u001b[43mros\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_severity_combined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Verify lengths\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X_resampled_combined) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_resampled_dr_combined) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_resampled_severity_combined)\n",
      "File \u001b[1;32mc:\\Users\\renat\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\renat\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\base.py:118\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n\u001b[0;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m )\n\u001b[1;32m--> 118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m \u001b[43marrays_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (X_, y_) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (X_, y_, output[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\renat\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\utils\\_validation.py:40\u001b[0m, in \u001b[0;36mArraysTransformer.transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m---> 40\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transfrom_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_props\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfrom_one(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_props)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_props[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_props[\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m     ]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;66;03m# We lost the y.index during resampling. We can safely use X.index to align\u001b[39;00m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;66;03m# them.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\renat\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\utils\\_validation.py:61\u001b[0m, in \u001b[0;36mArraysTransformer._transfrom_one\u001b[1;34m(self, array, props)\u001b[0m\n\u001b[0;32m     59\u001b[0m type_ \u001b[38;5;241m=\u001b[39m props[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 61\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m type_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# Dataset and DataLoader Setup for Combined Model\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Dataset with the appropriate transform\n",
    "dataset_combined = FundusDataset(csv_file=csv_file, img_dir=img_dir, transform=transform)\n",
    "# Prepare binary and severity dataset for combined model\n",
    "features_combined, label_dr_combined, label_severity_combined = [], [], []\n",
    "for img, label_dr, label_severity in dataset_combined:\n",
    "    features_combined.append(img.numpy().flatten())\n",
    "    label_dr_combined.append(label_dr)\n",
    "    label_severity_combined.append(label_severity)\n",
    "\n",
    "# Oversample both binary and severity label\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled_combined, y_resampled_dr_combined = ros.fit_resample(features_combined, label_dr_combined)\n",
    "_, y_resampled_severity_combined = ros.fit_resample(features_combined, label_severity_combined)\n",
    "# Verify lengths\n",
    "assert len(X_resampled_combined) == len(y_resampled_dr_combined) == len(y_resampled_severity_combined)\n",
    "# Create the resampled dataset for binary and severity combined\n",
    "resampled_dataset_combined = ResampledDataset(\n",
    "    features=X_resampled_binary,\n",
    "    label_dr=y_resampled_binary,\n",
    "    label_severity=y_resampled_severity_combined,\n",
    "    is_severity_task=False \n",
    ")\n",
    "\n",
    "\n",
    "# Split into train and test sets\n",
    "train_size_combined = int(0.8 * len(resampled_dataset_combined))\n",
    "test_size_combined = len(resampled_dataset_combined) - train_size_combined\n",
    "train_dataset_combined, test_dataset_combined = random_split(resampled_dataset_combined, [train_size_combined, test_size_combined])\n",
    "\n",
    "# DataLoaders for training and testing combined model\n",
    "train_loader_combined = DataLoader(train_dataset_combined, batch_size=8, shuffle=True, pin_memory=True)\n",
    "test_loader_combined = DataLoader(test_dataset_combined, batch_size=8, shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the InceptionResNetV2 model\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "class Stem(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Stem, self).__init__()\n",
    "        self.conv1 = BasicConv2d(3, 32, kernel_size=3, stride=2)\n",
    "        self.conv2 = BasicConv2d(32, 32, kernel_size=3)\n",
    "        self.conv3 = BasicConv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.branch0 = nn.MaxPool2d(3, stride=2)\n",
    "        self.branch1 = BasicConv2d(64, 96, kernel_size=3, stride=2)\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(160, 64, kernel_size=1),\n",
    "            BasicConv2d(64, 96, kernel_size=3)\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            BasicConv2d(160, 64, kernel_size=1),\n",
    "            BasicConv2d(64, 64, kernel_size=(7,1), padding=(3,0)),\n",
    "            BasicConv2d(64, 64, kernel_size=(1,7), padding=(0,3)),\n",
    "            BasicConv2d(64, 96, kernel_size=3)\n",
    "        )\n",
    "        self.branch4 = BasicConv2d(192, 192, kernel_size=3, stride=2)\n",
    "        self.branch5 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x = torch.cat([x0, x1], dim=1)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        x = torch.cat([x2, x3], dim=1)\n",
    "        x4 = self.branch4(x)\n",
    "        x5 = self.branch5(x)\n",
    "        x = torch.cat([x4, x5], dim=1)\n",
    "        return x\n",
    "\n",
    "class InceptionResNetA(nn.Module):\n",
    "    def __init__(self, scale=0.17):\n",
    "        super(InceptionResNetA, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.branch1 = BasicConv2d(384, 32, kernel_size=1)\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(384, 32, kernel_size=1),\n",
    "            BasicConv2d(32, 32, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            BasicConv2d(384, 32, kernel_size=1),\n",
    "            BasicConv2d(32, 48, kernel_size=3, padding=1),\n",
    "            BasicConv2d(48, 64, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.conv = nn.Conv2d(128, 384, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(384, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1(x)\n",
    "        branch2x1 = self.branch2(x)\n",
    "        branch3x1 = self.branch3(x)\n",
    "        outputs = [branch1x1, branch2x1, branch3x1]\n",
    "        x = torch.cat(outputs, 1)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = x * self.scale\n",
    "        return x + x\n",
    "\n",
    "class ReductionA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReductionA, self).__init__()\n",
    "        self.branch1 = nn.MaxPool2d(3, stride=2)\n",
    "        self.branch2 = BasicConv2d(384, 384, kernel_size=3, stride=2)\n",
    "        self.branch3 = nn.Sequential(\n",
    "            BasicConv2d(384, 256, kernel_size=1),\n",
    "            BasicConv2d(256, 256, kernel_size=3, padding=1),\n",
    "            BasicConv2d(256, 384, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch1(x)\n",
    "        x1 = self.branch2(x)\n",
    "        x2 = self.branch3(x)\n",
    "        x = torch.cat([x0, x1, x2], 1)\n",
    "        return x\n",
    "\n",
    "class InceptionResNetB(nn.Module):\n",
    "    def __init__(self, scale=0.1):\n",
    "        super(InceptionResNetB, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(1152, 192, kernel_size=1),\n",
    "            BasicConv2d(192, 160, kernel_size=(1,7), padding=(0,3)),\n",
    "            BasicConv2d(160, 192, kernel_size=(7,1), padding=(3,0))\n",
    "        )\n",
    "        self.branch2 = BasicConv2d(1152, 192, kernel_size=1)\n",
    "        self.conv = nn.Conv2d(384, 1152, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(1152, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1(x)\n",
    "        branch2x1 = self.branch2(x)\n",
    "        outputs = [branch1x1, branch2x1]\n",
    "        x = torch.cat(outputs, 1)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = x * self.scale\n",
    "        return x + x\n",
    "\n",
    "class ReductionB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReductionB, self).__init__()\n",
    "        self.branch1 = nn.MaxPool2d(3, stride=2)\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(1152, 256, kernel_size=1),\n",
    "            BasicConv2d(256, 384, kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            BasicConv2d(1152, 256, kernel_size=1),\n",
    "            BasicConv2d(256, 288, kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.branch4 = nn.Sequential(\n",
    "            BasicConv2d(1152, 256, kernel_size=1),\n",
    "            BasicConv2d(256, 288, kernel_size=3, padding=1),\n",
    "            BasicConv2d(288, 320, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch1(x)\n",
    "        x1 = self.branch2(x)\n",
    "        x2 = self.branch3(x)\n",
    "        x3 = self.branch4(x)\n",
    "        x = torch.cat([x0, x1, x2, x3], 1)\n",
    "        return x\n",
    "\n",
    "class InceptionResNetC(nn.Module):\n",
    "    def __init__(self, scale=0.2):\n",
    "        super(InceptionResNetC, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(2144, 192, kernel_size=1),\n",
    "            BasicConv2d(192, 224, kernel_size=(1,3), padding=(0,1)),\n",
    "            BasicConv2d(224, 256, kernel_size=(3,1), padding=(1,0))\n",
    "        )\n",
    "        self.branch2 = BasicConv2d(2144, 192, kernel_size=1)\n",
    "        self.conv = nn.Conv2d(448, 2144, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(2144, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1(x)\n",
    "        branch2x1 = self.branch2(x)\n",
    "        outputs = [branch1x1, branch2x1]\n",
    "        x = torch.cat(outputs, 1)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = x * self.scale\n",
    "        return x + x\n",
    "\n",
    "class InceptionResNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=2):  # 2 classes: non-DR and DR\n",
    "        super(InceptionResNetV2, self).__init__()\n",
    "        self.stem = Stem()\n",
    "        self.inception_resnet_a = nn.Sequential(\n",
    "            InceptionResNetA(),\n",
    "            InceptionResNetA(),\n",
    "            InceptionResNetA()\n",
    "        )\n",
    "        self.reduction_a = ReductionA()\n",
    "        self.inception_resnet_b = nn.Sequential(\n",
    "            InceptionResNetB(),\n",
    "            InceptionResNetB(),\n",
    "            InceptionResNetB()\n",
    "        )\n",
    "        self.reduction_b = ReductionB()\n",
    "        self.inception_resnet_c = nn.Sequential(\n",
    "            InceptionResNetC(),\n",
    "            InceptionResNetC(),\n",
    "            InceptionResNetC()\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(2144, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.inception_resnet_a(x)\n",
    "        x = self.reduction_a(x)\n",
    "        x = self.inception_resnet_b(x)\n",
    "        x = self.reduction_b(x)\n",
    "        x = self.inception_resnet_c(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Densenet 121\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, drop_rate=0.0):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        inter_channels = 4 * growth_rate\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_channels, inter_channels, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(inter_channels)\n",
    "        self.conv2 = nn.Conv2d(inter_channels, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        bottleneck_output = self.conv1(self.relu(self.bn1(x)))\n",
    "        bottleneck_output = self.conv2(self.relu(self.bn2(bottleneck_output)))\n",
    "        if self.drop_rate > 0:\n",
    "            bottleneck_output = F.dropout(bottleneck_output, p=self.drop_rate, training=self.training)\n",
    "        return torch.cat([x, bottleneck_output], 1)\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, num_layers, growth_rate, drop_rate=0.0):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(Bottleneck(in_channels, growth_rate, drop_rate))\n",
    "            in_channels += growth_rate\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.pool = nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn(x))\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes=4):  # 4 classes: severity levels\n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            DenseBlock(64, 6, 32),\n",
    "            Transition(64 + 6 * 32, 128),\n",
    "            DenseBlock(128, 12, 32),\n",
    "            Transition(128 + 12 * 32, 256),\n",
    "            DenseBlock(256, 24, 32),\n",
    "            Transition(256 + 24 * 32, 512),\n",
    "            DenseBlock(512, 16, 32)\n",
    "        )\n",
    "        self.fc = nn.Linear(512 + 16 * 32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define criterion, optimizer, and other hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 10\n",
    "patience = 5\n",
    "\n",
    "# Train the binary model (InceptionResNetV2) for DR detection\n",
    "def train_binary_model(model, dataloader, num_epochs,patience , device=device):\n",
    "    model.train()\n",
    "    dataloader=train_loader_inception\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "    scaler = GradScaler()\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    start_time = time.time()  # Start timing\n",
    "    print (\"Training binary (inception resnetv2) start\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            # Unpack batch; ignore label_severity if present\n",
    "            for inputs, label_dr, _ in dataloader:\n",
    "                inputs, label_dr = inputs.to(device), label_dr.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            # with autocast():\n",
    "                # Forward pass for binary classification (Non-DR vs DR)\n",
    "            dr_pred = model(inputs)\n",
    "                # print(\"Model Output:\", dr_pred)\n",
    "            #     with autocast(dtype=torch.float32):\n",
    "            loss = criterion(dr_pred, label_dr)\n",
    "            # print(\"Loss:\", loss.item())\n",
    "            # Check if loss is NaN\n",
    "            if torch.isnan(loss).any():\n",
    "                print(f\"NaN loss encountered at epoch {epoch + 1}, step {i + 1}. Investigating...\")\n",
    "                return\n",
    "            # Backward pass and optimization\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(dr_pred, 1)\n",
    "            running_corrects += (preds == label_dr).sum().item()\n",
    "            total_samples += label_dr.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        epoch_acc = running_corrects / total_samples\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "        \n",
    "        # Early stopping check\n",
    "        early_stopping(epoch_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        if epoch_loss < early_stopping.best_score:\n",
    "            torch.save(model.state_dict(), \"binary_model_best.pth\")\n",
    "    \n",
    "    end_time = time.time()  # End timing\n",
    "    print(f'Training completed in {(end_time - start_time) / 60:.2f} minutes') \n",
    "    print('Binary model training complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for severity classification\n",
    "def prepare_data_for_severity(binary_model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Filter data dari binary model dan kembalikan data yang relevan untuk model severity.\n",
    "    \"\"\"\n",
    "    binary_model.eval()  # Set binary model ke evaluasi\n",
    "    severity_data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, label_dr, label_severity in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            # Prediksi dengan model binary\n",
    "            dr_preds = torch.argmax(binary_model(inputs), dim=1)\n",
    "\n",
    "            # Ambil hanya sampel dengan prediksi DR (label 1)\n",
    "            dr_indices = (dr_preds == 1).nonzero(as_tuple=True)[0]\n",
    "\n",
    "            if len(dr_indices) > 0:\n",
    "                filtered_inputs = inputs[dr_indices].cpu()\n",
    "                filtered_severity_label = label_severity[dr_indices].cpu()\n",
    "                # Filter valid severity labels (assuming [1, 4] is valid range before adjustment)\n",
    "                valid_indices = (filtered_severity_label >= 1) & (filtered_severity_label <= 4)\n",
    "                filtered_inputs = filtered_inputs[valid_indices]\n",
    "                filtered_severity_label = filtered_severity_label[valid_indices]\n",
    "                severity_data.extend(zip(filtered_inputs, filtered_severity_label))\n",
    "    \n",
    "    print(f\"Total severity samples prepared: {len(severity_data)}\")\n",
    "    return severity_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the severity model (DenseNet121) for DR severity classification\n",
    "def train_severity_model(model, dataloader, num_epochs,patience, device=device):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    scheduler = StepLR(optimizer, step_size=4, gamma=0.1)   \n",
    "    scaler = GradScaler()\n",
    "    class_weights = torch.tensor([ 0.0213, 0.0167, 0.0930, 0.2186]).to(device)  # Adjust based on your dataset\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    start_time = time.time()  # Start timing\n",
    "    print (\"Training severity (Densenet 121) start\")\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total_samples = 0\n",
    "        for i, (inputs, _, label_severity) in  enumerate(dataloader):\n",
    "            inputs, label_severity = inputs.to(device), label_severity.to(device)\n",
    "            label_severity -= 1  # Adjust labels to [0, 3] range for CrossEntropyLoss\n",
    "            # assert torch.all(label_saverity > 0),f\"Found label 0 in batch {i + 1}\"\n",
    "            # print(f\"label: min={label.min().item()}, max={label.max().item()}\")\n",
    "            # assert torch.all(label >= 1) and torch.all(label <= 4), \"label berada di luar rentang [1, 4]!\"\n",
    "            assert torch.all(label_severity >= 0) and torch.all(label_severity < 4), f\"Invalid label: {label_severity}\"\n",
    "            optimizer.zero_grad()\n",
    "            # print(np.unique(label.cpu().numpy()))  # Convert tensor to NumPy array before using np.unique\n",
    "            # print(f\"label: {label}\")  # Check the label in each batch\n",
    "            with autocast(), torch.autograd.detect_anomaly():\n",
    "                # Forward pass for severity classification (classes 1 to 4)\n",
    "                severity_pred = model(inputs)\n",
    "                loss = criterion(severity_pred, label_severity)  # label are already in [1, 2, 3, 4]\n",
    "            if torch.isnan(severity_pred).any() or torch.isinf(severity_pred).any():\n",
    "                print(f\"NaN or Inf detected in model output!\")\n",
    "                break\n",
    "            if torch.isnan(loss).any():\n",
    "                print(f\"NaN loss encountered at epoch {epoch + 1}, step {i + 1}. Investigating...\")\n",
    "                return\n",
    "            # Backward pass and optimization\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(severity_pred, 1)\n",
    "            # preds += 1 \n",
    "            running_corrects += (preds == label_severity).sum().item()\n",
    "            total_samples += label_severity.size(0)\n",
    "        epoch_loss = running_loss / len(severity_data)\n",
    "        epoch_acc = running_corrects.double() / total_samples\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "        # Scheduler step\n",
    "        scheduler.step()    \n",
    "        # Early stopping check\n",
    "        early_stopping(epoch_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        if epoch_loss < early_stopping.best_score:\n",
    "            torch.save(model.state_dict(), \"severity_model_best.pth\")\n",
    "\n",
    "    end_time = time.time()  # End timing\n",
    "    print(f'Training completed in {(end_time - start_time) / 60:.2f} minutes')      \n",
    "    print('Severity model training complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedInferenceModel(nn.Module):\n",
    "    def __init__(self, binary_model, severity_model):\n",
    "        \"\"\"\n",
    "        Menggabungkan model binary dan severity ke dalam pipeline inference.\n",
    "        \n",
    "        Parameters:\n",
    "            binary_model: Model untuk klasifikasi DR/Non-DR.\n",
    "            severity_model: Model untuk klasifikasi tingkat keparahan DR.\n",
    "        \"\"\"\n",
    "        super(CombinedInferenceModel, self).__init__()\n",
    "        self.binary_model = binary_model\n",
    "        self.severity_model = severity_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Step 1: Prediksi DR/Non-DR\n",
    "        dr_pred = self.binary_model(x)\n",
    "        dr_class = torch.argmax(dr_pred, dim=1)  # Prediksi kelas DR/Non-DR\n",
    "\n",
    "        # Step 2: Filter DR-positif gambar untuk klasifikasi severity\n",
    "        mask = (dr_class > 0)  # Ambil hanya DR-positif\n",
    "        \n",
    "        dr_images = x[mask]\n",
    "\n",
    "        severity_pred = None\n",
    "        if dr_images.size(0) > 0:\n",
    "            # Step 3: Prediksi tingkat keparahan untuk gambar DR-positif\n",
    "            severity_pred = self.severity_model(dr_images)\n",
    "        else:\n",
    "            severity_pred = torch.tensor([], device=x.device)  # Kosongkan tensor untuk konsistensi\n",
    "\n",
    "        return dr_pred, severity_pred\n",
    "\n",
    "\n",
    "def train_combined_model(model, dataloader, num_epochs, patience=5, device='cuda'):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)  # LR lebih stabil\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = GradScaler()\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_correct_dr = 0\n",
    "        epoch_correct_severity = 0\n",
    "        total_samples_dr = 0\n",
    "        total_samples_severity = 0\n",
    "\n",
    "        for i, (inputs, label_dr, label_severity) in enumerate(dataloader):\n",
    "            inputs, label_dr, label_severity = (\n",
    "                inputs.to(device),\n",
    "                label_dr.to(device),\n",
    "                label_severity.to(device),\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                dr_pred, severity_pred = model(inputs)\n",
    "\n",
    "                # DR Loss and Accuracy\n",
    "                loss_dr = criterion(dr_pred, label_dr)\n",
    "                _, dr_preds = torch.max(dr_pred, dim=1)\n",
    "                correct_dr = torch.sum(dr_preds == label_dr).item()\n",
    "                total_samples_dr += label_dr.size(0)\n",
    "\n",
    "                # Severity Loss and Accuracy\n",
    "                loss_severity = 0.0\n",
    "                if severity_pred is not None and severity_pred.size(0) > 0:\n",
    "                    mask = (label_dr > 0)\n",
    "                    severity_label = label_severity[mask]\n",
    "                    severity_pred = severity_pred[mask]\n",
    "\n",
    "                    if severity_label.size(0) > 0:\n",
    "                        loss_severity = criterion(severity_pred, severity_label)\n",
    "                        _, severity_preds = torch.max(severity_pred, dim=1)\n",
    "                        correct_severity = torch.sum(severity_preds == severity_label).item()\n",
    "                        epoch_correct_severity += correct_severity\n",
    "                        total_samples_severity += severity_label.size(0)\n",
    "\n",
    "                # Total Loss\n",
    "                total_loss = loss_dr + loss_severity\n",
    "\n",
    "            scaler.scale(total_loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            epoch_loss += total_loss.item()\n",
    "            epoch_correct_dr += correct_dr\n",
    "\n",
    "        # Epoch Metrics\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        dr_accuracy = epoch_correct_dr / total_samples_dr if total_samples_dr > 0 else 0.0\n",
    "        severity_accuracy = epoch_correct_severity / total_samples_severity if total_samples_severity > 0 else 0.0\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}, \"\n",
    "            f\"DR Accuracy: {dr_accuracy:.4f}, Severity Accuracy: {severity_accuracy:.4f}\"\n",
    "        )\n",
    "\n",
    "        early_stopping(avg_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "\n",
    "def evaluate_combined_model(model, dataloader, device='cuda'):\n",
    "    model.eval()\n",
    "    true_label_dr, pred_label_dr = [], []\n",
    "    true_label_severity, pred_label_severity = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, label_dr, label_severity in dataloader:\n",
    "            inputs, label_dr, label_severity = (\n",
    "                inputs.to(device),\n",
    "                label_dr.to(device),\n",
    "                label_severity.to(device),\n",
    "            )\n",
    "\n",
    "            dr_pred, severity_pred = model(inputs)\n",
    "            dr_preds = torch.argmax(dr_pred, dim=1)\n",
    "\n",
    "            true_label_dr.extend(label_dr.cpu().numpy())\n",
    "            pred_label_dr.extend(dr_preds.cpu().numpy())\n",
    "\n",
    "            if severity_pred is not None and severity_pred.size(0) > 0:\n",
    "                mask = (dr_preds == 1)\n",
    "                severity_preds = torch.argmax(severity_pred, dim=1)\n",
    "                true_label_severity.extend(label_severity[mask].cpu().numpy())\n",
    "                pred_label_severity.extend(severity_preds.cpu().numpy())\n",
    "\n",
    "    # Calculate Metrics\n",
    "    dr_accuracy = accuracy_score(true_label_dr, pred_label_dr)\n",
    "    dr_f1 = f1_score(true_label_dr, pred_label_dr, average='weighted')\n",
    "\n",
    "    if true_label_severity:\n",
    "        severity_accuracy = accuracy_score(true_label_severity, pred_label_severity)\n",
    "        severity_f1 = f1_score(true_label_severity, pred_label_severity, average='weighted')\n",
    "        print(f\"Severity Accuracy: {severity_accuracy:.4f}, Severity F1: {severity_f1:.4f}\")\n",
    "\n",
    "    print(f\"DR Accuracy: {dr_accuracy:.4f}, DR F1: {dr_f1:.4f}\")\n",
    "    if not true_label_severity:\n",
    "        print(\"No DR-positive samples found for severity evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train both models\n",
    "binary_model = InceptionResNetV2(num_classes=2).to(device)\n",
    "severity_model = DenseNet121(num_classes=4).to(device)\n",
    "\n",
    "# Latih binary model\n",
    "train_binary_model(binary_model, train_loader_inception, num_epochs=num_epochs, patience=patience)\n",
    "torch.save(binary_model.state_dict(), \"binary_model_best.pth\")  # Simpan model binary\n",
    "# Filter data untuk model severity\n",
    "severity_data = prepare_data_for_severity(binary_model, train_loader_inception, device)\n",
    "severity_dataloader = DataLoader(\n",
    "    severity_data, batch_size=8, shuffle=True, pin_memory=True\n",
    ")\n",
    "# Latih severity model\n",
    "train_severity_model(severity_model, severity_dataloader, num_epochs=num_epochs, patience=patience)\n",
    "torch.save(severity_model.state_dict(), \"severity_model_best.pth\")  # Simpan model severity\n",
    "# binary_model.eval()  # Set model ke mode evaluasi\n",
    "# severity_model.eval()\n",
    "# Gabungkan kedua model untuk inferensi\n",
    "combined_model = CombinedInferenceModel(binary_model, severity_model).to(device)\n",
    "\n",
    "# Evaluasi gabungan model\n",
    "evaluate_combined_model(combined_model, test_loader_combined, device=device)\n",
    "\n",
    "# Evaluation functions can similarly be split to test each model separately.\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Binary DR Classification Model\n",
    "def evaluate_binary_model(model, dataloader, device=device):\n",
    "    model.eval()\n",
    "    true_label = []\n",
    "    pred_label = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, label, _ in dataloader:\n",
    "            inputs, label = inputs.to(device), label.to(device)\n",
    "            \n",
    "            # Binary DR classification prediction\n",
    "            dr_pred = model.inception_resnet_v2(inputs)\n",
    "            dr_preds = torch.argmax(dr_pred, dim=1)  # Get the predicted DR class (0 or 1)\n",
    "            \n",
    "            true_label.extend(label.cpu().numpy())\n",
    "            pred_label.extend(dr_preds.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics for the binary classification\n",
    "    accuracy = accuracy_score(true_label, pred_label)\n",
    "    precision = precision_score(true_label, pred_label, average='weighted')\n",
    "    recall = recall_score(true_label, pred_label, average='weighted')\n",
    "    f1 = f1_score(true_label, pred_label, average='weighted')\n",
    "    \n",
    "    print(f'Binary DR Classification - Accuracy: {accuracy:.4f}')\n",
    "    print(f'Binary DR Classification - Precision: {precision:.4f}')\n",
    "    print(f'Binary DR Classification - Recall: {recall:.4f}')\n",
    "    print(f'Binary DR Classification - F1 Score: {f1:.4f}')\n",
    "\n",
    "\n",
    "# Evaluate Severity Classification Model\n",
    "def evaluate_severity_model(model, dataloader, device=device):\n",
    "    model.eval()\n",
    "    true_label = []\n",
    "    pred_label = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, label, _ in dataloader:\n",
    "            inputs, label = inputs.to(device), label.to(device)\n",
    "            \n",
    "            # Binary DR classification first to get DR predictions\n",
    "            dr_pred = model.inception_resnet_v2(inputs)\n",
    "            dr_preds = torch.argmax(dr_pred, dim=1)  # DR or Non-DR\n",
    "            \n",
    "            # Only evaluate severity for DR images\n",
    "            mask = (dr_preds == 1)  # DR images only (class 1)\n",
    "            dr_images = inputs[mask]\n",
    "            severity_label = label[mask]\n",
    "            \n",
    "            if dr_images.size(0) > 0:\n",
    "                # Severity classification only on DR images\n",
    "                severity_pred = model.densenet121(dr_images)\n",
    "                severity_preds = torch.argmax(severity_pred, dim=1)\n",
    "                \n",
    "                true_label.extend(severity_label.cpu().numpy())\n",
    "                pred_label.extend(severity_preds.cpu().numpy())\n",
    "    \n",
    "    if len(true_label) > 0:\n",
    "        # Calculate metrics for the severity classification\n",
    "        accuracy = accuracy_score(true_label, pred_label)\n",
    "        precision = precision_score(true_label, pred_label, average='weighted')\n",
    "        recall = recall_score(true_label, pred_label, average='weighted')\n",
    "        f1 = f1_score(true_label, pred_label, average='weighted')\n",
    "        \n",
    "        print(f'Severity Classification - Accuracy: {accuracy:.4f}')\n",
    "        print(f'Severity Classification - Precision: {precision:.4f}')\n",
    "        print(f'Severity Classification - Recall: {recall:.4f}')\n",
    "        print(f'Severity Classification - F1 Score: {f1:.4f}')\n",
    "    else:\n",
    "        print('No DR images were present in the batch for severity evaluation.')\n",
    "\n",
    "\n",
    "# Save model\n",
    "torch.save(combined_model.state_dict(), 'combined_model.pth')\n",
    "\n",
    "# Load model\n",
    "model = CombinedInferenceModel(num_classes_dr=2, num_classes_severity=4)\n",
    "model.load_state_dict(torch.load('combined_model.pth'))\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
